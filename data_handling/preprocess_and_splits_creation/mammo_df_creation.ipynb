{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create EMBED splits\n",
    "This notebook takes care of creating the train/val/test splits csv used throughout this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "path_to_root = \"/vol/biomedic3/mb121/shift_identification/\"\n",
    "sys.path.append(path_to_root)\n",
    "\n",
    "from data_handling.mammo import domain_maps, modelname_map, tissue_maps\n",
    "from default_paths import EMBED_ROOT\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create main EMBED csv \n",
    "These cells take care of merging the oroginal metadata and clinical csv, remove invalid views, convert density to numerical scale etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dicom = pd.read_csv(\n",
    "    EMBED_ROOT / \"tables/EMBED_OpenData_metadata.csv\", low_memory=False\n",
    ")[\n",
    "    [\n",
    "        \"InstanceNumber\",\n",
    "        \"anon_dicom_path\",\n",
    "        \"PixelSpacing\",\n",
    "        \"ImagerPixelSpacing\",\n",
    "        \"Rows\",\n",
    "        \"Columns\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "dicom = pd.read_csv(\n",
    "    EMBED_ROOT / \"tables/EMBED_OpenData_metadata_reduced.csv\", low_memory=False\n",
    ")\n",
    "print(len(dicom))\n",
    "dicom = dicom.merge(full_dicom, on=\"anon_dicom_path\")\n",
    "print(len(dicom))\n",
    "dicom[\"image_path\"] = (\n",
    "    dicom[\"empi_anon\"].astype(\"str\")\n",
    "    + \"/\"\n",
    "    + dicom[\"anon_dicom_path\"].str.split(\"/\").str[-1].str.split(\".dcm\").str[0]\n",
    "    + \".png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XCCL shouldn't be converted to CC so manually editing it\n",
    "dicom.loc[\n",
    "    (dicom[\"SeriesDescription\"] == \"RXCCL\") | (dicom[\"SeriesDescription\"] == \"LXCCL\"),\n",
    "    \"ViewPosition\",\n",
    "] = \"XCCL\"\n",
    "\n",
    "# Getting all rows with \"ViewPosition\" == Nan (but for which SeriesDescription is also not nan, as these are the ones subject to the data entry error)\n",
    "view_nan = dicom.loc[(dicom.ViewPosition.isna()) & (~dicom.SeriesDescription.isna())]\n",
    "\n",
    "# Drop these rows from\n",
    "dicom_no_nans = dicom[~dicom.index.isin(view_nan.index)]\n",
    "\n",
    "view_nan[\"ViewPosition\"] = view_nan[\"SeriesDescription\"].apply(\n",
    "    lambda x: \"CC\" if \"CC\" in x else (\"MLO\" if \"MLO\" in x else None)\n",
    ")\n",
    "\n",
    "dicom = pd.concat([dicom_no_nans, view_nan], axis=0, ignore_index=True)\n",
    "\n",
    "print(len(dicom))\n",
    "# Remove any duplicated images\n",
    "dicom = dicom.drop_duplicates(subset=\"anon_dicom_path\")\n",
    "# Remove spot compressed and magnified images\n",
    "dicom = dicom[dicom.spot_mag.isna()]\n",
    "# Remove invalid views\n",
    "dicom = dicom[dicom.ViewPosition.isin([\"CC\", \"MLO\"])]\n",
    "# Remove images from male clients\n",
    "dicom = dicom[dicom.PatientSex == \"F\"]\n",
    "print(len(dicom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any unnecessary fields from the DICOM imagewise dataframe (this may need to be updated in the future if other fields are deemed relevant)\n",
    "dicom = dicom[\n",
    "    [\n",
    "        \"empi_anon\",\n",
    "        \"acc_anon\",\n",
    "        \"image_path\",\n",
    "        \"FinalImageType\",\n",
    "        \"ImageLateralityFinal\",\n",
    "        \"ViewPosition\",\n",
    "        \"Manufacturer\",\n",
    "        \"ManufacturerModelName\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion dictionary to standardised naming of various fields in clincial metadata\n",
    "\n",
    "# Human reader BIRADS density assessment\n",
    "dens_conversion = {1.0: \"A\", 2.0: \"B\", 3.0: \"C\", 4.0: \"D\"}\n",
    "\n",
    "# Load in the clinical metadata\n",
    "mag = pd.read_csv(EMBED_ROOT / \"tables/EMBED_OpenData_clinical.csv\", low_memory=False)\n",
    "print(len(mag))\n",
    "# Remove cases from cases a valid BIRADS density assessment\n",
    "mag = mag[mag.tissueden.isin([1.0, 2.0, 3.0, 4.0])]\n",
    "mag.replace({\"tissueden\": dens_conversion}, inplace=True)\n",
    "\n",
    "\n",
    "# Keep important study metadata tags to join up with final aggregated dataframe at end of script\n",
    "mag = mag[[\"empi_anon\", \"tissueden\", \"study_date_anon\", \"acc_anon\"]].drop_duplicates(\n",
    "    subset=\"acc_anon\"\n",
    ")\n",
    "print(len(mag))\n",
    "\n",
    "# Convert to pandas datetime object\n",
    "mag[\"study_date_anon\"] = pd.to_datetime(mag[\"study_date_anon\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom.Manufacturer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider studies which have a valid link between the DICOM and clinical metadata\n",
    "print(len(dicom))\n",
    "df = mag.merge(dicom, on=[\"acc_anon\", 'empi_anon'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_repo_root = \"/vol/biomedic3/mb121/shift_identification/\"\n",
    "df.to_csv(Path(path_to_repo_root) / \"data_handling\" / \"embed_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = EMBED_ROOT / Path(\"images/png/1024x768\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(Path(path_to_root) / \"data_handling\" / \"embed_full.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        \"\"\"\n",
    "        For running EMBED code you need to first generate the csv\n",
    "        file used for this study by running the cells above\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "df[\"shortimgpath\"] = df[\"image_path\"]\n",
    "df[\"image_path\"] = df[\"image_path\"].apply(lambda x: image_dir / str(x))\n",
    "\n",
    "df[\"manufacturer_domain\"] = df.Manufacturer.apply(lambda x: domain_maps[x])\n",
    "\n",
    "# convert tissueden to trainable label\n",
    "df[\"tissueden\"] = df.tissueden.apply(lambda x: tissue_maps[x])\n",
    "\n",
    "df[\"SimpleModelLabel\"] = df.ManufacturerModelName.apply(lambda x: modelname_map[x])\n",
    "print(df.SimpleModelLabel.value_counts())\n",
    "df[\"ViewLabel\"] = df.ViewPosition.apply(lambda x: 0 if x == \"MLO\" else 1)\n",
    "\n",
    "df = df.dropna(\n",
    "    subset=[\n",
    "        \"tissueden\",\n",
    "        \"SimpleModelLabel\",\n",
    "        \"ViewLabel\",\n",
    "        \"image_path\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "df[\"tissueden\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.FinalImageType == \"2D\"]\n",
    "\n",
    "y = df.groupby(\"empi_anon\")[\"tissueden\"].unique().apply(lambda x: x[0]).values\n",
    "print(np.bincount(y) / np.bincount(y).sum())\n",
    "train_id, val_id = train_test_split(\n",
    "    df.empi_anon.unique(), test_size=0.4, random_state=33, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "val_test_df = df.loc[df[\"empi_anon\"].isin(val_id)]\n",
    "# Keep only one study by patient\n",
    "studies = (\n",
    "    val_test_df.groupby(\"empi_anon\")[\"acc_anon\"].unique().apply(lambda x: x[0]).values\n",
    ")\n",
    "# For testing filter out all studies for which there is more than the expected 4 images (L/R, MLO/CC).\n",
    "# These are the studies with failed images, images with unexpected stuff. To make sure that the\n",
    "# distribution of val and un-shifted test are the same. Otherwise it might falsily the results.\n",
    "weird = (\n",
    "    df.groupby(\"acc_anon\")[\"acc_anon\"]\n",
    "    .unique()\n",
    "    .index[\n",
    "        np.where(\n",
    "            df.groupby(\"acc_anon\")[\"shortimgpath\"]\n",
    "            .unique()\n",
    "            .apply(lambda x: len(x) != 4)\n",
    "            .values\n",
    "        )[0]\n",
    "    ]\n",
    ")\n",
    "val_test_df = val_test_df.loc[val_test_df[\"acc_anon\"].isin(studies)]\n",
    "val_test_df = val_test_df.loc[~val_test_df[\"acc_anon\"].isin(weird)]\n",
    "\n",
    "pd.crosstab(val_test_df[\"SimpleModelLabel\"], val_test_df[\"tissueden\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_df[\"combined_var\"] = val_test_df[\"SimpleModelLabel\"] + 10 * val_test_df[\"tissueden\"]\n",
    "val_test_df[\"combined_var\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = val_test_df.groupby(\"acc_anon\")[\"combined_var\"].unique()\n",
    "ids, y = tmp.index, tmp.apply(lambda x: x[0]).values\n",
    "test_id, val_id = train_test_split(ids, test_size=1200, random_state=33, stratify=y)\n",
    "print(\n",
    "    f\"N patients train: {train_id.shape[0]}, val: {val_id.shape[0]}, test {test_id.shape[0]}\"\n",
    ")  # noqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.loc[df.empi_anon.isin(train_id)]\n",
    "val_df = val_test_df.loc[val_test_df.acc_anon.isin(val_id)]\n",
    "test_df = val_test_df.loc[val_test_df.acc_anon.isin(test_id)]\n",
    "test_df[\"idx_in_original_test\"] = np.arange(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(test_df[\"SimpleModelLabel\"], test_df[\"tissueden\"], normalize=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(val_df[\"SimpleModelLabel\"], val_df[\"tissueden\"], normalize=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"/vol/biomedic3/mb121/shift_identification/experiments/train_embed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv(\"/vol/biomedic3/mb121/shift_identification/experiments/val_embed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"/vol/biomedic3/mb121/shift_identification/experiments/test_embed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
